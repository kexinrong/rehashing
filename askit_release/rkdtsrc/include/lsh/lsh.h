#ifndef __LSH_H__
#define __LSH_H__

#include <vector>
#include <utility>
#include <mpi.h>

typedef double point_type;


namespace knn {
   namespace lsh {

      /**
       * The limit of LSH hash values; the largest possible key is one less than this number.
       */
      const unsigned int LSH_KEY_MAX = (unsigned int)((1L<<32) - 5L);

    
      /**
       * Generates the random hash functions used by LSH.
       * \param a [out] The random projection vectors; an array of length K*L*dim (internally allocated).
       * \param b [out] Uniformly distributed random value(s); array of length K*L (interally allocated).
       * \param K The number of random projections used for each hash function.
       * \param L The number of hash functions to generate.
       * \param W The length of each segment of the projection line (points in the same segment hash to the same value).
       * \param dim The dimensionality of the data points.
       * \note Intended for internal use only.
       */
      void generateHashFunctions (double *& a, double *& b, long K, long L, double W, long dim);
   
 /** 
       * Generates random vectors and scalars used for hash functions.
       * \param       dim     The dimensionality of the data
       * \param       R       Search radius (Use rKSelect to determine).
       * \param       K       The number of random projections per hash table (higher=more restrictive).
       * \param       L       The number of independent hash tables (higher=fewer false negatives).
       * \param       a       [out] a dim*K*L array of normally distributed random values (allocated internally).
       * \param       b       [out] a K*L array of uniformly distributed random values (allocated internally).
       * \param       rPP     Used to combine the K projected values into a single hash key.
       */
      void setup (int dim, double R, long K, long L,
                      double *&rPP, double *& a, double *& b);  

 
      /**
       * Generates the random numbers used to combine the K hash keys into one.
       * \param K The number of random projections used.
       * \param rPP [out] An array of K uniform random values.
       * \note Inteded for internal use only.
       */
      void generateRandomNos (long K, double *&rPP);
     
   
   
	/**
	 * Compute the hash values (bucket IDs) for a given set of reference or query points.
	 * \param points The points to hash.
	 * \param num_points The number of points.
         * \param a Generated by setup.
         * \param b Generated by setup.
         * \param K The number of random projection vectors.
         * \param L The number of times to hash each point (a must contain at least L*K vectors).
         * \param dim The dimensionality of the data points and projection vectors.
         * \param rPP Generated by setup.
	 * \param bucketIDs [out] An externally allocated matrix of dimensions num_points*L, containing
	 * the L bucket IDs for each point; the key for point i in table l is at index l*num_points+i.
 	*/
	void compute_hash_values  (point_type *points, int num_points, 
                double *a, double *b, long K, long L, int dim, 
                double *rPP, unsigned int* bucketIDs);

 
      



     /**
      * Choose range value and number of project vectors for distributed LSH search, optionally using autotuning.
      * \param ref Reference points.
      * \param refIDs The global identifiers for each reference point.
      * \param query Query Points.
      * \param queryIDs The global identifiers for each query point.
      * \param n Total number of reference points.
      * \param m Total number of query points.
      * \param nLocal Number of locally stored reference points.
      * \param mLocal Number of locally stored query points.
      * \param dim Dimenionality of data points.
      * \param k Number of neighbors to find.
      * \param mult Search radius is equal to $\mu + \sigma \times mult$, where $\mu$ is the mean of the k-th neighbor distances,
      * and $\sigma$ is the standard deviation (Generally, a value of 1.0 works well).
      * \param bf The bucket factor (total number of buckets = bf*size).
      * \param r [out] The calculated search radius.
      * \param K [out] The calculated number of random projections to use for each hash function.
      * \param comm MPI communicator to use.
      * \param autotune If true or unspecified, use autotuning; if false, use fixed formula for K.
      * \param pointLimit The maximum number of reference points a process is allowed to have; if 0 or 
      * unspecified, defaults to 4 * n/size
      */
     void rKSelect(double *ref, long *refIDs,  double* query, long *queryIDs, long n, long m, int nLocal, int mLocal,
                         int dim, int k, double mult, int bf, 
                         double &r, long &K, MPI_Comm comm, bool autotune = true, int pointLimit = 0);
 



 
   /**
    * Find the k nearest reference points lying within distance range of each query point using distributed LSH with 
    * separate reference and query point sets.
    * \param ref an nlocal*dim matrix of data points (row-major)
    * \param refIDs An array of length nlocal containing the unique ID of each reference point stored locally.
    * \param query an mlocal*dim matrix of query points (row-major)
    * \param queryIDs An array of length mlocal containing the unique ID of each query point stored locally.
    * \param n Number of global reference points
    * \param m Number of global query points
    * \param nLocal Number of local reference points
    * \param mLocal Number of local query points
    * \param dim Dimensionality of reference/query points
    * \param range The search radius.
    * \param k The maximum number of (nearest) neighbors to return for each point.
    * \param K The number of hash functions per table.
    * \param Lmax The maximum number of iterations.
    * \param bucketfactor Use a number of outer buckets equal to bucketfactor*size; a higher value generally results in
    * improved load balance.
    * \param targetError The desired maximum relative mean error.
    * \param kNN [out] An empty vector to store the result.  The result will be stored as a row-major array with
    * m columns.  The ID of each neighbor is stored, along with the *square* of its distance from the query point.
    * The neighbors of the query point with ID i will be stored as determined by idToHomeRank.
    * \param outQueryIDs [out] The query point IDs corresponding to the result set stored by this process.
    * \param comm The MPI communicator to use (normally MPI_COMM_WORLD).
    * \param convAndTiming If true or unspecified, check convergence after each iteration and print timing/accuracy information.
    */
      void distPartitionedKQuery
              ( double* ref, long *refIDs, double *query, long* queryIDs, long n, long m, int nLocal,
                int mLocal, int dim, double range, int k, long K, long Lmax, int bucketFactor, double errorTarget,
                std::vector< std::pair<double,long> > &kNN, std::vector<long>& outQueryIDs, MPI_Comm comm,
                bool convAndTiming = true  );





   /**
    * All-nearest neighbor (reference points are query points) version of the LSH k-nearest search.
    * \param ref an nlocal*dim matrix of data points (row-major)
    * \param refIDs An array of length nlocal containing the unique ID of each reference point stored locally.
    * \param n Number of global reference points
    * \param nLocal Number of local reference points
    * \param dim Dimensionality of reference/query points
    * \param range The search radius.
    * \param k The maximum number of (nearest) neighbors to return for each point.
    * \param K The number of hash functions per table.
    * \param Lmax The maximum number of iterations.
    * \param bucketfactor Use a number of outer buckets equal to bucketfactor*size; a higher value generally results in
    * improved load balance.
    * \param targetError The desired maximum relative mean error.
    * \param kNN [out] An empty vector to store the result.  The result will be stored as a row-major array with
    * m columns.  The ID of each neighbor is stored, along with the *square* of its distance from the query point.
    * The neighbors of the query point with ID i will be stored as determined by idToHomeRank.
    * \param outQueryIDs [out] The query point IDs corresponding to the result set stored by this process.
    * \param comm The MPI communicator to use (normally MPI_COMM_WORLD).
    * \param pointLimit The maximum number of points allowed per process; If 0 or unspecified, defaults to 2*n/size.
    * \param convAndTiming If true or unspecified, check convergence after each iteration and print timing/accuracy information.
    */
      void distPartitionedKQuery
              ( double* ref, long *refIDs, long n, int nLocal,
                int dim, double range, int k, long K, long Lmax, int bucketFactor, double targetError,
                std::vector< std::pair<double,long> > &kNN, std::vector<long>& outQueryIDs, MPI_Comm comm, int pointLimit=0,
                bool convAndTiming = true );




      /**
       * Determine the "home" process for a given query point by its ID.  Used by Bo
       * \param id The query point's ID.
       * \param scan_np scan of number of points on each processor
       */
      inline int idToHomeRank(long id, std::vector<long> &scan_np) {
          int home = 0;
          for(int i = 0; i < scan_np.size(); i++) {
            if(id < scan_np[i]) {
                home = i;
                break;
            }
          }
          return home;
      }



      /**
       * Determine the "home" process for a given query point by its ID.  Used by distPartitionedKQuery.
       * \param id The query point's ID.
       * \param ppn Points per process (mGlobal/size).
       * \param size The size of the MPI communicator.
       */
      inline int idToHomeRank(long id, int ppn, int size) {
         int home = id/ppn;
         if(home >= size) home = size-1;
         return home;
      }



      /**
       * Perform an LSH query on a large data set with a small query point set (that can fit entirely into each process's memory).
       * \param ref an nlocal*dim matrix of data points (row-major)
       * \param refIDs An array of length nlocal containing the unique ID of each reference point stored locally.
       * \param query an mlocal*dim matrix of query points (row-major), MUST be identical on all processes.
       * \param queryIDs An array of length m containing the unique ID of each query, MUST be identical on all processes.
       * \param n Number of global reference points
       * \param m Number of global query points
       * \param nLocal Number of local reference points
       * \param dim Dimensionality of reference/query points
       * \param k The maximum number of (nearest) neighbors to return for each point.
       * \param Lmax The number of iterations to run.
       * \param numBuckets The number of hash buckets for each process to use.
       * \param kNN [out] An empty vector to store the result.  The result will be stored as a row-major array with
       * m columns.  The ID of each neighbor is stored, along with the *square* of its distance from the query point. 	
       * The neighbors of the query point with ID i will be stored as determined by idToHomeRank.  The results are stored 
       * ONLY at process with rank 0 in comm.
       * \param outQueryIDs [out] The query point IDs corresponding to the result set stored by this process.
       * \param comm The MPI communicator to use (normally MPI_COMM_WORLD).
       * \note This function will use auto-tuning to select the search radius and K.  This function
       * performs a fixed number of iterations and does not check for convergence as doing so does
       * not make sense for small query point sets. 
       */
      void distLSHreplicatedQ
              ( double* ref, long *refIDs, double *query, long* queryIDs, long n, long m, int nLocal,
                int dim, int k, long Lmax, int numBuckets, double rMultiplier, 
                std::vector< std::pair<double,long> > &kNN, std::vector<long>& outQueryIDs, MPI_Comm comm );


  }

}
#endif 
